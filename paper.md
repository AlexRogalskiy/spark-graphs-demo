# Реализация алгоритмов обработки графов в Apache Spark с нуля

графы
    - мотивация
    - алгоритмы
        - классические алгоритмы
            - BFS
            - DFS
        - распределенные алгоритмы
            - общая информация
            - думай как вершина
            - итеративные алгоритмы
                - зачем
                - Apache Spark
            - Pregel
                - описание
                - API
                - примеры псевдокод
            - GraphLab
                - описание
                - API
                - примеры псевдокод
            - PowerGraph
                - описание
                - API
                - примеры псевдокод
            - Apache Spark
                - планы запросов
                - итерации
            - Обобщенные реализации
                - связные компоненты
                - минимальное расстояние
                - топологическая сортировка
                - PageRank
            - Power-Law графы

# DISCLAMER

> Статья ставит целью с нуля реализовать алгоритмы распределенной обработки графов на Apache Spark, которые в силу своего большого размера невозможно обработать классическими алгоритмами на одной машине. Оптимизация производительности реализованных алгоритмов выходит за рамки текущей статьи.

# TLDR

В статье реализованы распределенные версии классических алгоритмов на графах при помощи Apache Spark. Алгоритмы составлены в соответствии с идеями из популярных фреймворков распределенной обработки графов: [Pregel](https://dl.acm.org/doi/abs/10.1145/1807167.1807184), [GraphLab](https://arxiv.org/abs/1408.2041) и [PowerGraph](https://www.usenix.org/conference/osdi12/technical-sessions/presentation/gonzalez), но с поправкой на [power-law](https://en.wikipedia.org/wiki/Power_law) графы (т.е. большинство вершин графа соединены с одной или несколькими вершинами), которых в реальном мире большинство.

# Мотивация

Однажды ко мне обратилась одна крупная ~~фруктовая~~ телефонная компания с просьбой подготовить для них курс по Apache Spark продвинутого уровня, и в нем обязательно должен быть раздел про обработку графов (Neo4j не предлагать). На тот момент я знал про классические алгоритмы обработки графов на базе DFS (поиск в глубину) и BFS (поиск в ширину). При этом неотъемлемым условием применения того или иного подхода является локальная поддержка стека (DFS) или очереди (BFS). Следовательно, классические алгоритмы можно применять для обработки графов, которые умещаются в память одной машины. В современном мире данные накапливаются очень быстро, и классические подходы, ориентированные на обработку графов в рамках одной машины, перестают работать. Интуитивно можно предположить, что необходимо разбивать граф на части, но каким образом и как потом их собирать вместе?

Я знал, что Apache Spark имеет ~~мертвый~~ [GraphX](https://spark.apache.org/docs/latest/graphx-programming-guide.html) и полуготовый [GraphFrames](https://graphframes.github.io/graphframes/docs/_site/index.html). Мне стало интересно разобраться в том, каким образом выполняется обработка огромных графов. Оказалось, что за последние 15 лет разработано несколько алгоритмов распределенной обработки графов, причем каждый подход оформлен в виде публикации в научном журнале. Я поставил себе цель разобраться в этих алгоритмах, и, следуя концепции zero-dependency, перенести их в Apache Spark. Текущая статья является отражением моих изысканий.

# Обзор подходов

Основные фреймворки для обработки больших и очень больших графов:

- [Pregel](https://dl.acm.org/doi/abs/10.1145/1807167.1807184) - синхронный фреймворк для обработки графов отдаленно напоминающий map-reduce (разработка Google), основанный на принципе обмена сообщений,
- [GraphLab](https://arxiv.org/abs/1408.2041) - асинхронный фреймворк для обработки графов с разделяемой памятью (разработка университета Карнеги — Меллона),
- [PowerGraph](https://www.usenix.org/conference/osdi12/technical-sessions/presentation/gonzalez) - фреймворк для обработки графов с синхронным и асинхронным подходом (разработка команды GraphLab).

## Думай как вершина

Все три фреймворка построены вокруг идеи "думай как вершина" (think like a vertex): при разработке алгоритмов можно использовать только ту информацию, до которой текущая вершина может дотянуться, т.е. можно использовать входящие и исходящие ребра графа, веса ребер, значение самой вершины и т.д.

## Итеративный процесс

Другой отличительной чертой распределенных алгоритмов является итеративная природа процессов вычислений на графах: необходимо выполнить один и тот же алгоритм несколько раз, чтобы получить конечный результат. Итеративность подразумевает синхронный алгоритм: запустить первую стадию, дождаться, когда все участники ответят, потом запустить вторую и т.д. Итеративность заложена в основу Pregel, PowerGraph также имеет синхронный режим работы. GraphLab является асинхронным фреймворком, и благодаря использованию разделяемой памяти алгоритм может запускаться на вершине сразу после предыдущего запуска, не дожидаясь завершения алгоритма на остальных узлах.

### Итеративность в Apache Spark

Управляющая программа (driver) в Apache Spark строит план запроса, который потом исполняется на воркерах (executors). Так каждая команда, например, фильтрация, преобразования, слияние и т.д., является всего лишь узлом в плане запроса. Благодаря этому факту, новые планы запросов можно строить на базе уже имеющихся планов.

Рассмотрим простой пример эволюции плана запроса:

1. Создать DataFrame из одной строки и одной колонки:

```python
df = spark.sql("select rand() as id")
df.explain()

== Physical Plan ==
*(1) Project [rand(1533802073737075276) AS id#49]
+- *(1) Scan OneRowRelation[]
```

2. Выполнить фильтрацию - к предыдущему плану добавился новый узел `Filter`:

```python
df = df.where("id > 0")
df.explain()

== Physical Plan ==
*(1) Filter (id#49 > 0.0)
+- *(1) Project [rand(1533802073737075276) AS id#49]
   +- *(1) Scan OneRowRelation[]
```

3. Изменить значение колонки `id` - добавился новый узел `Project`:

```python
df = df.select("id", F.rand())
df.explain()

== Physical Plan ==
*(1) Project [id#49, rand(-6415673197654941820) AS rand(-6415673197654941820)#51]
+- *(1) Filter (id#49 > 0.0)
   +- *(1) Project [rand(1533802073737075276) AS id#49]
      +- *(1) Scan OneRowRelation[]
```

4. Указанные действия можно выполнять и в цикле:

```python
for _ in range(5):
    df = df.where("id > rand()").select("id", F.rand())

df.explain()

== Physical Plan ==
*(1) Project [id#49, rand(263374480755633512) AS rand(263374480755633512)#159]
+- *(1) Filter (id#49 > rand(8987503485164949684))
   +- *(1) Filter (id#49 > rand(-1547883987418598842))
      +- *(1) Filter (id#49 > rand(-692100532660493196))
         +- *(1) Filter (id#49 > rand(4695896702299530223))
            +- *(1) Filter (id#49 > rand(6199414182906311709))
               +- *(1) Filter (id#49 > 0.0)
                  +- *(1) Project [rand(1533802073737075276) AS id#49]
                     +- *(1) Scan OneRowRelation[]
```

Возможность генерации плана в цикле будет использоваться для запуска итеративного процесса вычисления результата на графах.

Итоговый план запроса может быть очень большим, что можно отнести к недостаткам такого подхода. Тут стоит учитывать, что план будет иметь фрактальный рисунок: малая часть плана будет выглядеть как весь план, что облегчает анализ.

Так же к недостаткам можно отнести тот факт, что управляющая программа (driver) может не справиться с генерацией большого плана по причине нехватки ресурсов. Для решения этой проблемы можно использовать checkpoint: драйвер будет запускать исполнение плана по частям.

## Фреймворк Pregel

Фреймворк [Pregel](https://dl.acm.org/doi/abs/10.1145/1807167.1807184) был разработан в Google для обработки больших и очень больших графов и отдаленно напоминает map-reduce. Подобно map-reduce разработчик пишет алгоритм, который рассылается каждой вершине в графе. Процесс вычисления итогового результата выглядит следующим образом:

1. каждая вершина при помощи алгоритма может сформировать сообщение и отправить его соседям, которые находятся на другой стороне исходящего из вершины ребра;
1. все сообщения складываются в почтовый ящик каждой вершины (количество почтовых ящиков равно количеству вершин);
1. каждая вершина берет информацию из своего почтового ящика и формирует новое сообщение, которое отправляет соседям, при помощи указанного алгоритма.

Цепочка действий выше называется superstep (шаг). Для достижения итогового результата необходимо запустить алгоритм несколько раз. Конечный результат можно получить при достижении одного из двух условий:

- определенное количество шагов (superstep) выполнилось,
- ни у одной вершины нет новых сообщений.

На любом шаге вершина может деактивировать себя, чтобы сообщить планировщику, что она не будет участвовать в расчетах на следующем шаге (superstep), но планировщик активирует ее принудительно, если для нее поступят новые сообщения.

Также программист может определить ассоциативную (`(a + b) + c = a + (b + c)`) и коммутативную (`a + b = b + a`) операцию для слияния множества сообщений в одно для сокращения трафика при передаче сообщений.

*Примечание*: Pregel - это название реки в городе Кёнигсберг (современный Калининград), над которой были воздвигнуты семь мостов. Леонард Эйлер поставил себе задачу найти способ пройти по всем мостам, не проходя ни по одному из них дважды ([Wikipedia](https://ru.wikipedia.org/wiki/%D0%97%D0%B0%D0%B4%D0%B0%D1%87%D0%B0_%D0%BE_%D1%81%D0%B5%D0%BC%D0%B8_%D0%BA%D1%91%D0%BD%D0%B8%D0%B3%D1%81%D0%B1%D0%B5%D1%80%D0%B3%D1%81%D0%BA%D0%B8%D1%85_%D0%BC%D0%BE%D1%81%D1%82%D0%B0%D1%85)). Решение этой задачи считается первым в истории применением теории графов.

### Программный Интерфейс Pregel

Хотя весь код будет реализован в декларативном виде на базе Apache Spark DSL запросов, ниже приведен программный интерфейс фреймворка Pregel на Python. Идеи распределенных алгоритмов на графах на Pregel будут демонстрироваться в виде псевдокода при помощи указанного API.

```python
class PregelVertex(Protocol[VertexValue, EdgeValue, MessageValue]):

    @abstractmethod
    def compute(self, messages: List[MessageValue]) -> None:
        ...

    @abstractmethod
    def send_message(self, target_vertex_id, message: MessageValue):
        ...

    @abstractmethod
    @property
    def value(self) -> VertexValue:
        ...

    @abstractmethod
    @value.setter
    def value(self, new_value: VertexValue) -> None:
        ...

    @abstractmethod
    def out_edges(self) -> List[EdgeValue]:
        ...
```

Пояснения:

- `PregelVertex` представляет собой абстракцию над вершиной графа, которая имеет три типовых параметра:
    1. `VertexValue` тип данных, которые могут храниться в вершине,
    1. `EdgeValue` тип данных для абстракции над ребрами;
    1. `MessageValue` тип данных передаваемых сообщений.
- метод `compute` принимает на вход список сообщений и вычисляет новое значение, которое сохраняется внутри текущего объекта,
- метод `send_message` отправляет сообщение указанной вершине,
- метод `value` представляет собой `property` для доступа к текущему значению,
- метод `out_edges` позволяет получить список исходящих из текущей вершины ребер.

Оригинальная публикация допускает отправку сообщений произвольным вершинам. Концептуально, если отправлять сообщения несуществующим вершинам, то можно создавать новые вершины. На практике список адресатов составляют только из списка непосредственных соседей. Такое ограничение позволяет применять более эффективные алгоритмы разбиения графов с учетом локальности данных.

### Задача "Связные компоненты" (Connected Components)

Решение задачи поиска связных компонент позволяет разбить граф на подграфы, между которыми нет связей ([Wikipedia](https://ru.wikipedia.org/wiki/%D0%9A%D0%BE%D0%BC%D0%BF%D0%BE%D0%BD%D0%B5%D0%BD%D1%82%D0%B0_%D1%81%D0%B2%D1%8F%D0%B7%D0%BD%D0%BE%D1%81%D1%82%D0%B8_%D0%B3%D1%80%D0%B0%D1%84%D0%B0)). Иными словами, можно разбить вершины и ребра графа на непересекающиеся множества. В результате каждая вершина должна быть помечена тегом, который позволяет определить ее принадлежность к определенному подграфу.

Алгоритм на Pregel выглядит следующим образом:

```python
class CCPregelVertex(PregelVertex[int, Tuple[CCVertex, CCVertex], int]):

    def __init__(self, id: int):
        self.id = id
        self.value = id

    def compute(self, messages: List[int]) -> None:
        min_message_value = min(messages)

        if self.value > min_message_value:
            self.value = min_message_value

            for _, target in self.out_edges():
                self.send_message(target.id, self.value)
        
```

Комментарии к коду:

- `CCPregelVertex` наследует `PregelVertex`, где типовые параметры:
    1. `int` - тип значения, т.е. номер компонента связности/подграфа, к которому относится текущая вершина;
    1. `Tuple[CCVertex, CCVertex]` - тип ребра в формате: (исходная вершина, конечная вершина);
    1. `int` - тип сообщения, т.е. номер подграфа, в котором должны жить соседние вершины.
- изначально предполагается, что в графе нет ребер, а значит каждая вершина является компонентом связности/подграфом;
- метод `compute` корректирует номер подграфа, в котором находится текущая вершина:
    1. на вход приходят сообщения, которые были отправлены текущей вершине;
    1. выполняется поиск минимального сообщения;
    1. минимальное сообщение сравнивается с текущим значением - минимальное из двух будет являться номером подграфа, который содержит текущую вершину;
    1. если значение в текущей вершине было обновлено, то оповестить об этом соседей.
- реализация остальных методов исключена, т.к. по большей части зависит от окружения.

Процесс вычисления конечного результата является итеративным (планировщик выполняет superstep много раз), и программист сам должен управлять сходимостью алгоритма и прервать его, когда полученный результат будет устраивать. В худшем случае (когда граф - это связный список без циклов) количество необходимых шагов (superstep) будет линейно зависеть от диаметра самой большой связной компоненты.

### Алгоритм "Связные компоненты"

Решение для Apache Spark строится на базе Spark DSL запроса. Для исключения дублирования кода, основной алгоритм вынесен в функцию `pregel_cc` (подробные комментарии ниже):

```python
def pregel_cc(edges: DataFrame, values: DataFrame, steps: int):
    result_df = values
    for i in range(steps):
        result_df = (
            edges.join(result_df, col("src") == col("id"))
                .select(col("dst").alias("id"), col("value").alias("message"))
                .groupby(col("id")).agg(F.min("message").alias("message"))
                .join(result_df, "id", "right")
                .select("id", F.least("message", "value").alias("value"))
        )
        if i % 5 == 0:
            result_df = result_df.checkpoint()

    return result_df
```

Комментарии к коду:

- функция `pregel_cc` принимает на вход три параметра:
    1. `edges` - датафрейм с ребрами графа. В датафрейме обязательно должны быть две колонки:
        - `src` - исходная вершина,
        - `dst` - конечная вершина.
    1. `values` - датафрейм с вершинами графа. В датафрейме обязательно должны быть две колонки:
        - `id` - идентификатор вершины,
        - `value` - значение, сохраненное в вершине.
    1. `steps` - количество шагов (superstep), которое необходимо выполнить, чтобы алгоритм сошёлся.
- `result_df` - датафрейм, который аккумулирует в себе результирующий план запроса;
- каждые пять шагов (superstep) управляющая программа будет вычислять накопленный план.

Рассмотрим запрос поближе и укажем на аналогии с кодом на Python для вычисления связных компонент:

1. `edges.join(result_df, col("src") == col("id"))` позволяет соединить датафреймы ребер и вершин, так в результате появятся как минимум четыре колонки:
    1. `src` - исходная вершина;
    1. `dst` - конечная вершина;
    1. `id` - идентификатор вершины (равен `src`);
    1. `value` - текущее значение вершины (`src` и `id`). Это значение нужно отправить всем вершинам `dst`. В самом начале оно равно значению из колонки `id`.
2. `.select(col("dst").alias("id"), col("value").alias("message"))` формирует сообщение для каждой вершины. Фактически программа говорит: сейчас у вершины `src` значение `value`, каждая вершина `dst` должна об этом знать. На рисунке ниже можно найти соответствие этой инструкции коду для вычисления связных компонент на Pregel:

![Список сообщений](https://habrastorage.org/webt/aq/te/zj/aqtezjt-a8ac5ifdil72yspduie.png)

3. `.groupby(col("id")).agg(F.min("message").alias("message"))` позволяет вычислить итоговое сообщение. Вершина `dst` может получить много сообщений от разных `src` вершин, а значит необходимо выбрать из сообщений минимальное значение;

![Получение минимального сообщения](https://habrastorage.org/webt/2l/e8/9s/2le89s7hxlfkrs4m2iaesu19azo.png)

4. `.join(result_df, "id", "right")` позволяет соединить итоговые сообщения с датафреймом, в котором находятся текущие значения. Как минимум в итоге получится три колонки:
    1. `id` - идентификатор текущей вершины,
    1. `value` - текущее значение вершины,
    1. `message` - итоговое сообщение от всех соседей. Нужно проверить меньше ли оно, чем текущее значение `value`.
5. `.select("id", F.least("message", "value").alias("value"))` позволяет вычислить итоговое значение:
    1. `id` - текущая вершина,
    1. `F.least("message", "value")` - выбрать минимум между сообщением и текущим значением,
    1. `.alias("value")` - заменить текущее значение `value` в вершине `id` на вычисленное.

![Вычисление нового значения](https://habrastorage.org/webt/ro/nu/97/ronu97pru4bmrpxsqixkwnqejm0.png)

6. `result_df = (...)` позволяет актуализировать значения вершин. Эта операция аналогична рассылке сообщений, но со всех вершин и сразу всем.

![Рассылка сообщений](https://habrastorage.org/webt/kv/ix/af/kvixaf4_kjvlmskjocjpvw3vkg8.png)

### Пример работы алгоритма "Связные компоненты"

![Исходный граф](https://habrastorage.org/webt/yz/gg/jh/yzggjhrflf_8ey-htgoixqbhvng.png)

Граф, представленный на картинке выше содержит две связные компоненты:

1. вершины {1,2,3,4,5},
1. вершины {6}.

Приведенный граф можно сгенерировать при помощи следующей функции:

```python
def small_graph():
    """Generates a small graph for tests"""
    verties = [ (x,) for x in range(1, 7) ]
    verties_df = (
        spark
            .createDataFrame(verties)
            .toDF("id")
    )
    edges = [ (1, 2, 1), (1, 3, 5), (2, 3, 1), (3, 4, 1), (4, 5, 1), (6, 6, 1) ]
    edges_df = (
        spark
            .createDataFrame(edges)
            .toDF("src", "dst", "weight")
    )
    return edges_df, verties_df
```

Подготовка данных:

```python
edges_df, vertices_df = small_graph()
```

Проследим как меняются значения в вершинах:

![Изменение значений](https://habrastorage.org/webt/6c/zf/3e/6czf3e2jzzw_nw1goob3-wpq3x8.png)

1. Начальное состояние (каждая вершина - свой собственный компонент связности/подграф):

```python
pregel_cc_df = vertices_df.withColumn("value", col("id"))
pregel_cc_df.show()
```

2. Выполним один шаг (superstep) - вершины 2 и 3 напрямую связаны с вершиной 1, поэтому для них значение `value` равно 1:

```python
pregel_cc_df = pregel_cc(edges_df, pregel_cc_df, 1)
pregel_cc_df.show()
```

3. Выполним еще один шаг (superstep) - вершина 4 напрямую связана с вершиной 3, до нее дошло значение `value` равное 1:

```python
pregel_cc_df = pregel_cc(edges_df, pregel_cc_df, 1)
pregel_cc_df.show()
```

4. Выполним еще один шаг (superstep) - вершина 5 напрямую связана с вершиной 4, до нее дошло значение `value` равное 1:

```python
pregel_cc_df = pregel_cc(edges_df, pregel_cc_df, 1)
pregel_cc_df.show()
```

5. Выполним еще один шаг (superstep) - изменений больше нет, алгоритм сошёлся:

```python
pregel_cc_df = pregel_cc(edges_df, pregel_cc_df, 1)
pregel_cc_df.show()
```

Таким образом, получилось два компонента связности: 1 и 6.

Стоит заметить, что нумерация компонентов не обязательно непрерывно возрастает на единицу: компоненты связности используют в качестве своих идентификаторов значение идентификатора одной из вершин, входящих в подграф. Этот факт необходимо учитывать, если нужно будет посчитать общее число компонентов связности или выполнить другую аналитику при помощи этой информации.

Реализованный алгоритм останавливается только, когда определенное количество шагов было выполнено. Заинтересованный читатель может реализовать остановку алгоритма по отсутствию новых сообщений самостоятельно. Для этого необходимо добавить новую колонку типа `boolean` под именем `value_changed`, значение которой необходимо установить в `True`, если `F.least("message", "value") != col("value")`. Когда алгоритм сойдется, изменений значения колонки `value` не будет, а следовательно, все строки будут иметь значение `False` в колонке `value`.
