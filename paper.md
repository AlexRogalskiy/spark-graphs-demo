# Распределенная обработка графов в Apache Spark

# DISCLAMER

> Статья ставит целью продемонстрировать подход к распределенной обработке графов, которые в силу своего большого размера невозможно обработать классическими алгоритмами на одной машине. Оптимизация производительности реализованных алгоритмов выходит за рамки текущей статьи.

# TLDR

В статье реализованы распределенные версии классических алгоритмов на графах при помощи Apache Spark. Алгоритмы реализуют идеи из популярных фреймворков обработки графов: [Pregel](https://dl.acm.org/doi/abs/10.1145/1807167.1807184), [GraphLab](https://arxiv.org/abs/1408.2041) и [PowerGraph](https://www.usenix.org/conference/osdi12/technical-sessions/presentation/gonzalez), но с поправкой на [power-law](https://en.wikipedia.org/wiki/Power_law) графы (т.е. большинство вершин графа соединены с одной или несколькими вершинами), которых в реальном мире большинство.

# Мотивация

Как то раз ко мне обратилась одна крупная ~~фруктовая~~ телефонная компания с просьбой подготовить для них курс по Apache Spark продвинутого уровня, и в нем обязательно должен быть раздел про обработку графов (Neo4j не предлагать). На тот момент я знал про классические алгоритмы обработки графов, знал, что они строятся на базе DFS (поиск в глубину) или BFS (поиск в ширину). При этом неотъемлимым условием применения того или иного подхода является поддержка стэка (DFS) или очереди (BFS). Следовательно, классические алгоритмы можно применять для обработки графов, которые умещаются в память одной машины. В современном мире данные накапливаются очень быстро, и классические подходы, ориентированные на обработку графов в рамках одной машины, перестают работать. Интуитивно можно предположить, что необходимо разбивать граф на части, но как потом их собирать вместе?

Я знал, что Apache Spark имеет ~~мертвый~~ [GraphX](https://spark.apache.org/docs/latest/graphx-programming-guide.html) и полуготовый [GraphFrames](https://graphframes.github.io/graphframes/docs/_site/index.html). Мне стало интересно узнать, каким образом выполняется обработка огромных графов. Оказалось, что за последние 15 лет разработано несколько алгоритмов распределенной обработки графов. Причем каждый подход оформлен в виде публикации в научном журнале. Я поставил себе цель разобраться в этих алгоритмах, и, следуя концепции zero-dependency, перенести эти идеи в Apache Spark. Текущая статья является отражением моих изысканий.

# Обзор подходов

Основные фреймворки для обработки больших и очень больших графов:

- [Pregel](https://dl.acm.org/doi/abs/10.1145/1807167.1807184) - синхронный фреймворк для обработки графов по принципу map-reduce (разработка Google),
- [GraphLab](https://arxiv.org/abs/1408.2041) - aсинхронный фреймворк для обработки графов с разделяемой памятью (разработка университета Карнеги — Меллона),
- [PowerGraph](https://www.usenix.org/conference/osdi12/technical-sessions/presentation/gonzalez) - фреймворк для обработки графов с синхронным и асинхронным подходом (разработка команды GraphLab).

## Думай как вершина

Все три фреймворка построены вокруг идеи "думай как вершина" (think like a vertex): при разработке алгоритмов можно использовать только ту информацию, до которой текущая вершина может дотянуться, т.е. можно использовать ребра графа, веса, значение самой вершины и т.д. Разработанный алгоритм многократно запускается на каждой вершине до тех пор, пока процесс не сойдется. Сходимость процесса контролируется самим программистом.

## Фреймворк Pregel

Фреймворк [Pregel](https://dl.acm.org/doi/abs/10.1145/1807167.1807184) был разработан в Google для обработки больших и очень больших графов и отдаленно напоминает map-reduce.

Подобно map-reduce разработчик пишет алгоритм, который рассылается каждой вершине в графе. Процесс вычисления итогового результата выглядит следующим образом:

1. каждая вершина при помощи алгоритма может сформировать сообщение и отправить его соседям, которые находятся на другой стороне, относительно ребер, исходящих из текущей вершины;
1. все сообщения складываются в почтовый ящик каждой вершины (количество почтовых ящиков равно количеству вершин);
1. каждая вершина берет информацию из своего почтового ящика и формирует новое сообщение, которое отправляет соседям, при помощи указанного алгоритма.

Цепочка действий выше называется superstep (шаг). Для достижения итогового результата необходимо запустить алгоритм несколько раз. Конечный результат можно получить при достижении одного из двух условий:

- определенное количество шагов (superstep) выполнилось,
- ни у одной вершины нет новых сообщений.

На любом шаге вершина может деактивировать себя, чтобы сообщить планировщику, что она не будет участвовать в расчетах на следующем шаге (superstep), но планировщик активирует ее принудительно, если для нее поступят сообщения на обработку.

Дополнительно программист может определить ассоциативную (`(a + b) + c = a + (b + c)`) и коммутативную (`a + b = b + a`) операцию для слияния множества сообщений в одно для сокращения трафика при передаче сообщений.
